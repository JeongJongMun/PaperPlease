{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models.openai import ChatOpenAI\n",
    "from langchain.schema.runnable import ConfigurableField\n",
    "from operator import itemgetter\n",
    "from langchain.schema.runnable import RunnableLambda\n",
    "from langchain.schema import StrOutputParser\n",
    "\n",
    "chat_model = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", temperature=0)\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Tell me a joke about {input}\"\n",
    ").configurable_alternatives(\n",
    "    ConfigurableField(id=\"prompt\"),\n",
    "    default_key=\"GPT3\",\n",
    "    GPT4=ChatPromptTemplate.from_template(\"Write a short poem about {input}\"),\n",
    ")\n",
    "chain_t = prompt | chat_model | StrOutputParser()\n",
    "\n",
    "def update_config(input):\n",
    "    return chain_t.with_config(configurable={'prompt': input['_prompt']})\n",
    "\n",
    "chain_with_config = lambda input: chain_t.with_config(configurable={'prompt': input['_prompt']}).invoke(input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_with_config({\"input\": \"beer\", \"_prompt\": \"GPT4\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = RunnableLambda(update_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.invoke({\"input\": \"beer\", \"_prompt\": \"GPT4\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from setup import toolset, retriever, prompt_chat\n",
    "from operator import itemgetter\n",
    "import langchain\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.agents.format_scratchpad import format_log_to_str\n",
    "from langchain.agents.output_parsers import ReActSingleInputOutputParser\n",
    "from langchain.cache import InMemoryCache\n",
    "from langchain.chat_models import ChatOpenAI, ChatCohere\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.schema.prompt import PromptValue\n",
    "from langchain.schema.runnable import ConfigurableField, RunnableLambda, RunnablePassthrough\n",
    "from langchain.tools.render import render_text_description\n",
    "from langchain.prompts.chat import ChatPromptValue\n",
    "from langchain.schema.runnable.base import RunnableBinding\n",
    "\n",
    "# print \n",
    "def pp(p):\n",
    "    print(p)\n",
    "    print()\n",
    "    return p\n",
    "\n",
    "def tt(t):\n",
    "    print(type(t))\n",
    "    print()\n",
    "    return t\n",
    "\n",
    "# Cache\n",
    "langchain.llm_cache = InMemoryCache()\n",
    "# Memory\n",
    "memory = ConversationBufferMemory(memory_key=\"history\", return_messages=True)\n",
    "# ChatModel & ConfigurableField\n",
    "chat_model = ChatOpenAI(model=\"gpt-3.5-turbo-1106\", \n",
    "                        temperature=0.9).configurable_alternatives(\n",
    "                                            ConfigurableField(id=\"chatmodel\"),\n",
    "                                            default_key=\"GPT3\",\n",
    "                                            GPT4=ChatOpenAI(model=\"gpt-4-1106-preview\"),\n",
    "                                            Cohere=ChatCohere())\n",
    "\n",
    "def config_chat(input):\n",
    "    return chat_model.with_config(configurable={'chatmodel': input['_chatmodel']})\n",
    "\n",
    "llm_with_stop = chat_model.bind(stop=[\"\\nObservation\"])\n",
    "\n",
    "# Chain\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(\n",
    "        input=itemgetter(\"input\"),\n",
    "        context=RunnableLambda(lambda x: retriever.get_relevant_documents(x[\"input\"])),\n",
    "        chat_history=RunnableLambda(lambda x: memory.load_memory_variables(x[\"input\"])[\"history\"]),\n",
    "        tools=RunnableLambda(lambda x: render_text_description(toolset)),\n",
    "        tool_names=RunnableLambda(lambda x: \", \".join([t.name for t in toolset])),\n",
    "        agent_scratchpad=RunnableLambda(lambda x: format_log_to_str(x[\"intermediate_steps\"])),\n",
    "    )\n",
    "    | prompt_chat | RunnableLambda(pp) | RunnableLambda(tt)\n",
    "    | config_chat | RunnableLambda(pp) | RunnableLambda(tt)\n",
    "    | llm_with_stop | RunnableLambda(pp) | RunnableLambda(tt)\n",
    "    | ReActSingleInputOutputParser()\n",
    ")\n",
    "# AgentExecutor with ConfigurableField\n",
    "agent_executor = AgentExecutor(agent=chain, tools=toolset, \n",
    "                                verbose=True, memory=memory,                                 \n",
    "                                max_execution_time=60, max_iterations=5,\n",
    "                                handle_parsing_errors=True, early_stopping_method=\"generate\")\n",
    "\n",
    "c = RunnableLambda(tt) | RunnableLambda(pp) | agent_executor | RunnableLambda(pp)\n",
    "\n",
    "c.invoke({\"input\": \"beer\", \"_chatmodel\": \"GPT3\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_with_config = lambda input: RunnableLambda(llm_with_stop.with_config(configurable={'chatmodel': input['_chatmodel']}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models.openai import ChatOpenAI\n",
    "chat_model = ChatOpenAI(model=\"gpt-4-1106-preview\", temperature=0.3, streaming=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input =\"\"\"\n",
    "Correctly order the execution of non-interactive zero-knowledge proofs with Zorc from A to H. Zocrates is a tool that makes it easy to implement non-interactive zero-knowledge proofs\n",
    "(a) Computes a witness for the compiled program\n",
    "(b) Generate a Solidity contract for Verifier Smart Contract\n",
    "(c) Verify transaction\n",
    "(d) Create Sudoku Zokrates Verification Circuit\n",
    "(e) Creates a proving key and a verification key using “toxic waste”\n",
    "(f) Compile Verification Circuit\n",
    "(g) Deploy Smart Contract to Blockchain\n",
    "(h) Generate Proof\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To correctly order the execution of non-interactive zero-knowledge proofs using Zokrates, follow these steps:\n",
      "\n",
      "1. (d) Create Sudoku Zokrates Verification Circuit - First, you need to create the verification circuit for the specific computation you want to prove, in this case, a Sudoku puzzle.\n",
      "\n",
      "2. (f) Compile Verification Circuit - After creating the circuit, you compile it to generate the arithmetic representation that Zokrates can work with.\n",
      "\n",
      "3. (e) Creates a proving key and a verification key using “toxic waste” - With the compiled circuit, you then use the Zokrates setup process to generate a proving key (for creating proofs) and a verification key (for verifying proofs). The \"toxic waste\" refers to the randomness used in this process that must be securely discarded to ensure the security of the system.\n",
      "\n",
      "4. (a) Computes a witness for the compiled program - Once you have the proving key, you compute a witness for the specific instance of the problem you are proving (e.g., a solution to the Sudoku puzzle).\n",
      "\n",
      "5. (h) Generate Proof - Using the proving key and the witness, you generate a cryptographic proof that attests to the correctness of the witness without revealing it.\n",
      "\n",
      "6. (b) Generate a Solidity contract for Verifier Smart Contract - Zokrates can generate a Solidity smart contract that includes the verification key and a function to verify proofs on the Ethereum blockchain.\n",
      "\n",
      "7. (g) Deploy Smart Contract to Blockchain - The generated Solidity contract is then deployed to the blockchain, enabling on-chain verification of proofs.\n",
      "\n",
      "8. (c) Verify transaction - Finally, the proof is submitted to the blockchain along with a transaction, and the deployed smart contract verifies the proof using the verification function.\n",
      "\n",
      "So, the correct order is: d, f, e, a, h, b, g, c.\n"
     ]
    }
   ],
   "source": [
    "ans = chat_model.invoke(input)\n",
    "print(ans.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
